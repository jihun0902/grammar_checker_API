{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BART.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1vxpxltXL2pFdbhYIp0ZG2JN7KoAYr0ou","authorship_tag":"ABX9TyPJJ23bQEytWtVpHMMScnw4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vS52wkDKz1jJ"},"source":["! pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9twUjGNL0B5s"},"source":["cd drive/MyDrive/LXPER"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKY1vPYg0C-t"},"source":["import pandas as pd\n","import numpy as np\n","\n","data = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter=\"\\t\", header=None)[:2000]\n","test_data = pd.read_csv(\"./cola_public/raw/in_domain_dev.tsv\", delimiter=\"\\t\", header=None)[:2000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xigi4_jv0EkU"},"source":["from transformers import BartForSequenceClassification, BartTokenizer\n","import torch\n","use_cuda = True\n","\n","model = BartForSequenceClassification.from_pretrained('facebook/bart-large')\n","if use_cuda and torch.cuda.is_available():\n","    model.cuda()\n","model.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KTCdwjmw0I8V"},"source":["from transformers import AdamW\n","import torch.nn as nn\n","import torch.optim as optim\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=1e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGRKVs8_0YWm"},"source":["tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n","text_batch = list(data.iloc[:,3])\n","labels = list(data.iloc[:,1])\n","\n","\n","encoding = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True)\n","input_ids = encoding['input_ids']\n","attention_mask = encoding['attention_mask']\n","print(input_ids.shape)\n","print(attention_mask.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbbAPQo70eMG"},"source":["encoding['labels'] = torch.tensor(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YCL3HskY0fYl"},"source":["model.resize_token_embeddings(len(tokenizer))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4kQaR__0gnA"},"source":["device = 'cuda:0'\n","model = model.to(device)\n","encoding = encoding.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8N_XBM40ho5"},"source":["for epoch in range(3):\n","    for i in range(data.shape[0]):\n","        input = encoding['input_ids'][i].view(1, -1)\n","        mask = encoding['attention_mask'][i].view(1, -1)\n","        label = encoding['labels'][i].view(-1)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(input, mask, labels=label)\n","        loss = criterion(output.logits, label)\n","        print(loss)\n","        print('EPOCH:',epoch, '%:', round(i/data.shape[0], 4))\n","        loss.backward()\n","        optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tj3FIjFE0jFi"},"source":["model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKtXE50m0lCY"},"source":["test_text = list(test_data.iloc[:,3])\n","test_label = list(test_data.iloc[:,1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3y5cmjR0meG"},"source":["test_encoding = tokenizer(test_text, return_tensors='pt', padding=True, truncation=True)\n","\n","test_encoding = test_encoding.to(device)\n","test_input_ids = test_encoding['input_ids']\n","test_attention_mask = test_encoding['attention_mask']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYn0UECv0oR9"},"source":["pred = []\n","for i in range(test_data.shape[0]):\n","        input = test_encoding['input_ids'][i].view(1, -1)\n","        mask = test_encoding['attention_mask'][i].view(1, -1)\n","        \n","        output = model(input, mask)\n","        output = int(output.logits.argmax())\n","        pred.append(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLCOnZA_0qA2"},"source":["from sklearn.metrics import accuracy_score\n","\n","accuracy_score(test_label, pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FiAaz-uNOHDK"},"source":["torch.save(model.state_dict(), './models/bart_statedict')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0NlQ9CCOyMk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yjlwb28NOyKH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"32Zl4W6xOyHp"},"source":["test_encoding = tokenizer(['I are a boy'], return_tensors='pt', padding=True, truncation=True).to(device)\n","test_input_ids = test_encoding['input_ids']\n","test_attention_mask = test_encoding['attention_mask']\n","\n","input = test_encoding['input_ids'].view(1, -1)\n","mask = test_encoding['attention_mask'].view(1, -1)        \n","output = model(input, mask)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7ilChdqOx6H"},"source":[""],"execution_count":null,"outputs":[]}]}